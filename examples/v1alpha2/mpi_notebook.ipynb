{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "import fairing\n",
    "\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config as k8s_config\n",
    "\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "namespace = fairing_utils.get_current_k8s_namespace()\n",
    "\n",
    "logging.info(f\"Running in project {GCP_PROJECT}\")\n",
    "logging.info(f\"Running in namespace {namespace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to start mpi-operator job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First thing first,  set up the credentials if needed. \n",
    "\n",
    "If you are runing on your kubeflow cluster this should not be an issues and you can contiue to the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define mpi job. \n",
    "\n",
    "This example is based aroud the tensorflow-benchmark found [here](https://github.com/kubeflow/mpi-operator/blob/master/examples/v1alpha1/tensorflow-benchmarks.yaml). To make this example we have defined the complete job below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi_job = f\"\"\"\n",
    "apiVersion: kubeflow.org/v1alpha2\n",
    "kind: MPIJob\n",
    "metadata:\n",
    "  name: tensorflow-benchmarks\n",
    "spec:\n",
    "  slotsPerWorker: 1\n",
    "  cleanPodPolicy: Running\n",
    "  mpiReplicaSpecs:\n",
    "    Launcher:\n",
    "      replicas: 1\n",
    "      template:\n",
    "         spec:\n",
    "           containers:\n",
    "           - image: mpioperator/tensorflow-benchmarks:latest\n",
    "             name: tensorflow-benchmarks\n",
    "             command:\n",
    "             - mpirun\n",
    "             - --allow-run-as-root\n",
    "             - -np\n",
    "             - \"2\"\n",
    "             - -bind-to\n",
    "             - none\n",
    "             - -map-by\n",
    "             - slot\n",
    "             - -x\n",
    "             - NCCL_DEBUG=INFO\n",
    "             - -x\n",
    "             - LD_LIBRARY_PATH\n",
    "             - -x\n",
    "             - PATH\n",
    "             - -mca\n",
    "             - pml\n",
    "             - ob1\n",
    "             - -mca\n",
    "             - btl\n",
    "             - ^openib\n",
    "             - python\n",
    "             - scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\n",
    "             - --model=resnet101\n",
    "             - --batch_size=64\n",
    "             - --variable_update=horovod\n",
    "    Worker:\n",
    "      replicas: 2\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - image: mpioperator/tensorflow-benchmarks:latest\n",
    "            name: tensorflow-benchmarks\n",
    "            resources:\n",
    "              limits:\n",
    "                nvidia.com/gpu: 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retrying\n",
    "from kubernetes import client\n",
    "from kubernetes import watch as k8s_watch\n",
    "from table_logger import TableLogger\n",
    "\n",
    "#from kubeflow.tfjob.utils import utils\n",
    "\n",
    "tbl = TableLogger(\n",
    "  columns='NAME,STATE,TIME',\n",
    "  colwidth={'NAME': 30, 'STATE':20, 'TIME':30},\n",
    "  border=False)\n",
    "\n",
    "@retrying.retry(wait_fixed=1000, stop_max_attempt_number=20)\n",
    "def watch_k8s(name=None, namespace=None, timeout_seconds=600):\n",
    "  \"\"\"Watch the created or patched InferenceService in the specified namespace\"\"\"\n",
    "\n",
    "  #if namespace is None:\n",
    "    #namespace = utils.get_default_target_namespace()\n",
    "\n",
    "  stream = k8s_watch.Watch().stream(\n",
    "    client.CustomObjectsApi().list_namespaced_custom_object,\n",
    "    MPI_JOB_GROUP,\n",
    "    MPI_JOB_VERSION,\n",
    "    namespace,\n",
    "    MPI_JOB_PLURAL,\n",
    "    timeout_seconds=timeout_seconds)\n",
    "\n",
    "  for event in stream:\n",
    "    mpijob = event['object']\n",
    "    mpijob_name = mpijob['metadata']['name']\n",
    "    if name and name != mpijob_name:\n",
    "      continue\n",
    "    else:\n",
    "      status = ''\n",
    "      update_time = ''\n",
    "      last_condition = mpijob.get('status', {}).get('conditions', [])[-1]\n",
    "      status = last_condition.get('type', '')\n",
    "      update_time = last_condition.get('lastTransitionTime', '')\n",
    "\n",
    "      tbl(mpijob_name, status, update_time)\n",
    "\n",
    "      if name == mpijob_name:\n",
    "        if status == 'Succeeded' or status == 'Failed':\n",
    "          break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a python mpijob client\n",
    "\n",
    "This sectin contains some helper code that is a modified version of the [tfjob client](https://github.com/kubeflow/tf-operator/blob/master/sdk/python/docs/TFJobClient.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "import time\n",
    "\n",
    "def is_running_in_k8s():\n",
    "  return os.path.isdir('/var/run/secrets/kubernetes.io/')\n",
    "\n",
    "MPI_JOB_GROUP = \"kubeflow.org\"\n",
    "MPI_JOB_PLURAL = \"mpijobs\"\n",
    "MPI_JOB_NAME_LABEL = \"job-mpi\"\n",
    "MPI_JOB_VERSION = \"v1alpha2\"\n",
    "APISERVER_TIMEOUT = 120\n",
    "\n",
    "class MPIJobClient(object):\n",
    "\n",
    "  def __init__(self, config_file=None, context=None, # pylint: disable=too-many-arguments\n",
    "               client_configuration=None, persist_config=True):\n",
    "    \"\"\"\n",
    "    TFJob client constructor\n",
    "    :param config_file: kubeconfig file, defaults to ~/.kube/config\n",
    "    :param context: kubernetes context\n",
    "    :param client_configuration: kubernetes configuration object\n",
    "    :param persist_config:\n",
    "    \"\"\"\n",
    "    if config_file or not is_running_in_k8s():\n",
    "      config.load_kube_config()\n",
    "        #config_file=config_file,\n",
    "        #context=context,\n",
    "        #client_configuration=client_configuration,\n",
    "        #persist_config=persist_config)\n",
    "    else:\n",
    "      config.load_incluster_config()\n",
    "\n",
    "    self.custom_api = client.CustomObjectsApi()\n",
    "    self.core_api = client.CoreV1Api()\n",
    "\n",
    "  def create(self, mpijob, namespace=None):\n",
    "    \"\"\"\n",
    "    Create the TFJob\n",
    "    :param tfjob: tfjob object\n",
    "    :param namespace: defaults to current or default namespace\n",
    "    :return: created tfjob\n",
    "    \"\"\"\n",
    "\n",
    "    if namespace is None:\n",
    "      namespace = utils.set_tfjob_namespace(tfjob)\n",
    "\n",
    "    try:\n",
    "      outputs = self.custom_api.create_namespaced_custom_object(\n",
    "        MPI_JOB_GROUP,\n",
    "        MPI_JOB_VERSION,\n",
    "        namespace,\n",
    "        MPI_JOB_PLURAL,\n",
    "        mpijob)\n",
    "    except client.rest.ApiException as e:\n",
    "      raise RuntimeError(\n",
    "        \"Exception when calling CustomObjectsApi->create_namespaced_custom_object:\\\n",
    "         %s\\n\" % e)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "  def is_job_succeeded(self, name, namespace=None):\n",
    "    \"\"\"Returns true if the TFJob succeeded; false otherwise.\n",
    "    :param name: The TFJob name.\n",
    "    :param namespace: defaults to current or default namespace.\n",
    "    :return: True or False\n",
    "    \"\"\"\n",
    "    mpijob_status = self.get_job_status(name, namespace=namespace)\n",
    "    return mpijob_status.lower() == \"succeeded\"\n",
    "\n",
    "\n",
    "  def get_job_status(self, name, namespace=None):\n",
    "    \"\"\"Returns TFJob status, such as Running, Failed or Succeeded.\n",
    "    :param name: The TFJob name.\n",
    "    :param namespace: defaults to current or default namespace.\n",
    "    :return: Object TFJob status\n",
    "    \"\"\"\n",
    "    if namespace is None:\n",
    "      namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    mpijob = self.get(name, namespace=namespace)\n",
    "    last_condition = mpijob.get(\"status\", {}).get(\"conditions\", [])[-1]\n",
    "    return last_condition.get(\"type\", \"\")\n",
    "\n",
    "  def wait_for_condition(self, name,\n",
    "                         expected_condition,\n",
    "                         namespace=None,\n",
    "                         timeout_seconds=1200,\n",
    "                         polling_interval=30,\n",
    "                         status_callback=None):\n",
    "    \"\"\"Waits until any of the specified conditions occur.\n",
    "    :param name: Name of the job.\n",
    "    :param expected_condition: A list of conditions. Function waits until any of the\n",
    "           supplied conditions is reached.\n",
    "    :param namespace: defaults to current or default namespace.\n",
    "    :param timeout_seconds: How long to wait for the job.\n",
    "    :param polling_interval: How often to poll for the status of the job.\n",
    "    :param status_callback: (Optional): Callable. If supplied this callable is\n",
    "           invoked after we poll the job. Callable takes a single argument which\n",
    "           is the job.\n",
    "    :return: Object TFJob status\n",
    "    \"\"\"\n",
    "\n",
    "    #if namespace is None:\n",
    "    #  namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    for _ in range(round(timeout_seconds/polling_interval)):\n",
    "\n",
    "      mpi_job = None\n",
    "      mpi_job = self.get(name, namespace=namespace)\n",
    "\n",
    "      if mpi_job:\n",
    "        if status_callback:\n",
    "          status_callback(mpi_job)\n",
    "\n",
    "        # If we poll the CRD quick enough status won't have been set yet.\n",
    "        conditions = mpi_job.get(\"status\", {}).get(\"conditions\", [])\n",
    "        # Conditions might have a value of None in status.\n",
    "        conditions = conditions or []\n",
    "        for c in conditions:\n",
    "          if c.get(\"type\", \"\") in expected_condition:\n",
    "            return mpi_job\n",
    "\n",
    "      time.sleep(polling_interval)\n",
    "\n",
    "    raise RuntimeError(\n",
    "      \"Timeout waiting for TFJob {0} in namespace {1} to enter one of the \"\n",
    "      \"conditions {2}.\".format(name, namespace, expected_condition), tfjob)\n",
    "\n",
    "  def get(self, name=None, namespace=None, watch=False, timeout_seconds=600): #pylint: disable=inconsistent-return-statements\n",
    "    \"\"\"\n",
    "    Get the tfjob\n",
    "    :param name: existing tfjob name, if not defined, the get all tfjobs in the namespace.\n",
    "    :param namespace: defaults to current or default namespace\n",
    "    :param watch: Watch the TFJob if `True`.\n",
    "    :param timeout_seconds: How long to watch the job..\n",
    "    :return: tfjob\n",
    "    \"\"\"\n",
    "    if namespace is None:\n",
    "      namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    if name:\n",
    "      if watch:\n",
    "        tfjob_watch(\n",
    "          name=name,\n",
    "          namespace=namespace,\n",
    "          timeout_seconds=timeout_seconds)\n",
    "      else:\n",
    "        thread = self.custom_api.get_namespaced_custom_object(\n",
    "          MPI_JOB_GROUP,\n",
    "          MPI_JOB_VERSION,\n",
    "          namespace,\n",
    "          MPI_JOB_PLURAL,\n",
    "          name,\n",
    "          async_req=True)\n",
    "\n",
    "        mpijob = None\n",
    "        try:\n",
    "          mpijob = thread.get(APISERVER_TIMEOUT)\n",
    "        except multiprocessing.TimeoutError:\n",
    "          raise RuntimeError(\"Timeout trying to get TFJob.\")\n",
    "        except client.rest.ApiException as e:\n",
    "          raise RuntimeError(\n",
    "            \"Exception when calling CustomObjectsApi->get_namespaced_custom_object:\\\n",
    "            %s\\n\" % e)\n",
    "        except Exception as e:\n",
    "          raise RuntimeError(\n",
    "            \"There was a problem to get TFJob {0} in namespace {1}. Exception: \\\n",
    "            {2} \".format(name, namespace, e))\n",
    "        return mpijob\n",
    "    else:\n",
    "      if watch:\n",
    "        watch_k8s(\n",
    "            namespace=namespace,\n",
    "            timeout_seconds=timeout_seconds)\n",
    "      else:\n",
    "        thread = self.custom_api.list_namespaced_custom_object(\n",
    "          MPI_JOB_GROUP,\n",
    "          MPI_JOB_VERSION,\n",
    "          namespace,\n",
    "          MPI_JOB_PLURAL,\n",
    "          async_req=True)\n",
    "\n",
    "        tfjobs = None\n",
    "        try:\n",
    "          tfjobs = thread.get(constants.APISERVER_TIMEOUT)\n",
    "        except multiprocessing.TimeoutError:\n",
    "          raise RuntimeError(\"Timeout trying to get TFJob.\")\n",
    "        except client.rest.ApiException as e:\n",
    "          raise RuntimeError(\n",
    "            \"Exception when calling CustomObjectsApi->list_namespaced_custom_object:\\\n",
    "            %s\\n\" % e)\n",
    "        except Exception as e:\n",
    "          raise RuntimeError(\n",
    "            \"There was a problem to list TFJobs in namespace {0}. \\\n",
    "            Exception: {1} \".format(namespace, e))\n",
    "        return tfjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the mpi client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpi_job_client = MPIJobClient(config_file=\"PATH/.kube/config\") # if you run locally\n",
    "mpi_job_client = MPIJobClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi_job_body = yaml.safe_load(mpi_job)\n",
    "mpi_job = mpi_job_client.create(mpi_job_body, namespace=namespace)  \n",
    "\n",
    "logging.info(f\"Created job {namespace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the job to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job takes roughtly 20 minutes to finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name=\"tensorflow-benchmarks\"\n",
    "mpi_job = mpi_job_client.wait_for_condition(train_name, expected_condition=[\"Succeeded\", \"Failed\"], namespace=namespace, timeout_seconds=1200)\n",
    "\n",
    "if mpi_job_client.is_job_succeeded(train_name, namespace):\n",
    "    print(\"The job succeded\")\n",
    "    logging.info(f\"TFJob {namespace}.{train_name} succeeded\")\n",
    "else:\n",
    "    raise ValueError(f\"TFJob {namespace}.{train_name} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the logs from the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"$(kubectl -n {namespace} get pods -l mpi_job_name=tensorflow-benchmarks-complete,mpi_role_type=launcher -o name)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ POD_NAME=tensorflow-benchmarks-complete-worker-0\n",
      "+ shift\n",
      "+ /opt/kube/kubectl exec tensorflow-benchmarks-complete-worker-0 -- /bin/sh -c     PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess \"env\" -mca ess_base_jobid \"4289331200\" -mca ess_base_vpid 1 -mca ess_base_num_procs \"3\" -mca orte_node_regex \"tensorflow-benchmarks-complete-launcher-hfx[2:88],tensorflow-benchmarks-complete-worker-[1:0-1]@0(3)\" -mca orte_hnp_uri \"4289331200.0;tcp://10.44.1.28:38135\" -mca pml \"ob1\" -mca btl \"^openib\" -mca plm \"rsh\" --tree-spawn -mca orte_parent_uri \"4289331200.0;tcp://10.44.1.28:38135\" -mca plm_rsh_agent \"/etc/mpi/kubexec.sh\" -mca orte_default_hostfile \"/etc/mpi/hostfile\" -mca hwloc_base_binding_policy \"none\" -mca rmaps_base_mapping_policy \"slot\" -mca pmix \"^s1,s2,cray,isolated\"\n",
      "+ POD_NAME=tensorflow-benchmarks-complete-worker-1\n",
      "+ shift\n",
      "+ /opt/kube/kubectl exec tensorflow-benchmarks-complete-worker-1 -- /bin/sh -c     PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess \"env\" -mca ess_base_jobid \"4289331200\" -mca ess_base_vpid 2 -mca ess_base_num_procs \"3\" -mca orte_node_regex \"tensorflow-benchmarks-complete-launcher-hfx[2:88],tensorflow-benchmarks-complete-worker-[1:0-1]@0(3)\" -mca orte_hnp_uri \"4289331200.0;tcp://10.44.1.28:38135\" -mca pml \"ob1\" -mca btl \"^openib\" -mca plm \"rsh\" --tree-spawn -mca orte_parent_uri \"4289331200.0;tcp://10.44.1.28:38135\" -mca plm_rsh_agent \"/etc/mpi/kubexec.sh\" -mca orte_default_hostfile \"/etc/mpi/hostfile\" -mca hwloc_base_binding_policy \"none\" -mca rmaps_base_mapping_policy \"slot\" -mca pmix \"^s1,s2,cray,isolated\"\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0513 05:27:21.394623 139942447605568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "W0513 05:27:21.404230 139942447605568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0513 05:27:21.404545 139942447605568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0513 05:27:21.403889 140110499780416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "W0513 05:27:21.522368 140110499780416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0513 05:27:21.522703 140110499780416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2020-05-13 05:27:21.891188: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-05-13 05:27:21.892358: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-05-13 05:27:21.901782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2020-05-13 05:27:21.989705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:21.990920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5504a60 executing computations on platform CUDA. Devices:\n",
      "2020-05-13 05:27:21.990942: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2020-05-13 05:27:21.994226: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2020-05-13 05:27:21.994449: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54d9dc0 executing computations on platform Host. Devices:\n",
      "2020-05-13 05:27:21.994467: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-05-13 05:27:21.994748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:21.995832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-05-13 05:27:21.996061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-05-13 05:27:21.998302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:22.000227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-05-13 05:27:22.000760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-05-13 05:27:22.003192: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-05-13 05:27:22.004858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-05-13 05:27:22.011034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-13 05:27:22.011240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.012150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.013047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-05-13 05:27:22.013168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-05-13 05:27:22.076071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2020-05-13 05:27:22.112669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-13 05:27:22.113347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-05-13 05:27:22.113431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-05-13 05:27:22.113812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.115152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.117053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10798 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "TensorFlow:  1.14\n",
      "Model:       resnet101\n",
      "Dataset:     imagenet (synthetic)\n",
      "Mode:        training\n",
      "SingleSess:  False\n",
      "Batch size:  128 global\n",
      "             64 per device\n",
      "Num batches: 100\n",
      "Num epochs:  0.01\n",
      "Devices:     ['horovod/gpu:0', 'horovod/gpu:1']\n",
      "NUMA bind:   False\n",
      "Data format: NCHW\n",
      "Optimizer:   sgd\n",
      "Variables:   horovod\n",
      "==========\n",
      "Generating training model\n",
      "W0513 05:27:22.164944 139942447605568 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:134: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "2020-05-13 05:27:22.166865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.167899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x532de90 executing computations on platform CUDA. Devices:\n",
      "2020-05-13 05:27:22.167922: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2020-05-13 05:27:22.171396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2020-05-13 05:27:22.171597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x53280a0 executing computations on platform Host. Devices:\n",
      "2020-05-13 05:27:22.171636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-05-13 05:27:22.171860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.172745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-05-13 05:27:22.172953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-05-13 05:27:22.247981: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:22.271630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-05-13 05:27:22.318357: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-05-13 05:27:22.398044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-05-13 05:27:22.437531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-05-13 05:27:22.504911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-13 05:27:22.505234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.506235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.507091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-05-13 05:27:22.508224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "W0513 05:27:22.595870 139942447605568 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:266: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "2020-05-13 05:27:22.631232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-13 05:27:22.631402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-05-13 05:27:22.631492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-05-13 05:27:22.633516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.634632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:22.635576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10798 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "TensorFlow:  1.14\n",
      "Model:       resnet101\n",
      "Dataset:     imagenet (synthetic)\n",
      "Mode:        training\n",
      "SingleSess:  False\n",
      "Batch size:  128 global\n",
      "             64 per device\n",
      "Num batches: 100\n",
      "Num epochs:  0.01\n",
      "Devices:     ['horovod/gpu:0', 'horovod/gpu:1']\n",
      "NUMA bind:   False\n",
      "Data format: NCHW\n",
      "Optimizer:   sgd\n",
      "Variables:   horovod\n",
      "==========\n",
      "Generating training model\n",
      "W0513 05:27:22.674517 140110499780416 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:134: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0513 05:27:23.135070 140110499780416 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:266: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0513 05:27:30.116048 140110499780416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0513 05:27:30.181177 139942447605568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Initializing graph\n",
      "W0513 05:27:33.133054 139942447605568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:92: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0513 05:27:33.133515 139942447605568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:104: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Initializing graph\n",
      "W0513 05:27:34.217799 139942447605568 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2267: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "W0513 05:27:34.443904 140110499780416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:92: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0513 05:27:34.444417 140110499780416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:104: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2020-05-13 05:27:35.555405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:35.556369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-05-13 05:27:35.556499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-05-13 05:27:35.556613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:35.556707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-05-13 05:27:35.556817: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-05-13 05:27:35.556913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-05-13 05:27:35.557003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-05-13 05:27:35.557092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-13 05:27:35.557680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:35.559162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:35.559992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-05-13 05:27:35.560100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-13 05:27:35.560176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-05-13 05:27:35.560244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-05-13 05:27:35.560521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:35.561427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:35.562226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10798 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "W0513 05:27:35.581969 140110499780416 deprecation.py:323] From /tensorflow/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2267: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "2020-05-13 05:27:37.222491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:37.225614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-05-13 05:27:37.225778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-05-13 05:27:37.225903: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:37.226008: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-05-13 05:27:37.226105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-05-13 05:27:37.226241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-05-13 05:27:37.226342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-05-13 05:27:37.226439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-13 05:27:37.227059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:37.230479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:37.231350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-05-13 05:27:37.231461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-05-13 05:27:37.231528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-05-13 05:27:37.231614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-05-13 05:27:37.232110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:37.234971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-05-13 05:27:37.236004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10798 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2020-05-13 05:27:37.332627: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0513 05:27:38.585818 139942447605568 session_manager.py:500] Running local_init_op.\n",
      "I0513 05:27:38.769573 139942447605568 session_manager.py:502] Done running local_init_op.\n",
      "2020-05-13 05:27:39.010474: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0513 05:27:40.304113 140110499780416 session_manager.py:500] Running local_init_op.\n",
      "I0513 05:27:40.454643 140110499780416 session_manager.py:502] Done running local_init_op.\n",
      "Running warm up\n",
      "Running warm up\n",
      "2020-05-13 05:27:48.448075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:48.659069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-05-13 05:27:48.939925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-05-13 05:27:49.250652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO NET/Socket : Using [0]eth0:10.44.2.5<0>\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO NET/IB : No device found.\n",
      "NCCL version 2.4.7+cuda10.0\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Setting affinity for GPU 0 to 01\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO NET/Socket : Using [0]eth0:10.44.3.5<0>\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "2020-05-13 05:27:52.736873: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-05-13 05:27:52.809108: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO NET/IB : No device found.\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Setting affinity for GPU 0 to 01\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS\n",
      "2020-05-13 05:27:52.990924: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Channel 00 :    0   1\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Channel 01 :    0   1\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Ring 00 : 1 -> 0 [receive] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Ring 00 : 0 -> 1 [receive] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Ring 00 : 1 -> 0 [send] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO include/net.h:24 -> 2\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Ring 01 : 1 -> 0 [receive] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Ring 01 : 0 -> 1 [send] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Ring 01 : 0 -> 1 [receive] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO Ring 01 : 1 -> 0 [send] via NET/Socket/0\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\n",
      "tensorflow-benchmarks-complete-worker-1:20:24 [0] NCCL INFO comm 0x7f467c34e190 rank 1 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO comm 0x7f6d9c3128b0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\n",
      "tensorflow-benchmarks-complete-worker-0:20:24 [0] NCCL INFO Launch mode Parallel\n",
      "2020-05-13 05:27:54.654933: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "Done warm up\n",
      "Step\tImg/sec\ttotal_loss\n",
      "Done warm up\n",
      "Step\tImg/sec\ttotal_loss\n",
      "1\timages/sec: 21.3 +/- 0.0 (jitter = 0.0)\t8.299\n",
      "1\timages/sec: 21.3 +/- 0.0 (jitter = 0.0)\t8.362\n",
      "10\timages/sec: 21.5 +/- 0.1 (jitter = 0.3)\t8.529\n",
      "10\timages/sec: 21.5 +/- 0.1 (jitter = 0.4)\t8.515\n",
      "20\timages/sec: 21.5 +/- 0.1 (jitter = 0.3)\t8.263\n",
      "20\timages/sec: 21.5 +/- 0.1 (jitter = 0.3)\t8.485\n",
      "30\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.330\n",
      "30\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.282\n",
      "40\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.492\n",
      "40\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.334\n",
      "50\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.392\n",
      "50\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.411\n",
      "60\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.378\n",
      "60\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.330\n",
      "70\timages/sec: 21.7 +/- 0.0 (jitter = 0.2)\t8.424\n",
      "70\timages/sec: 21.7 +/- 0.0 (jitter = 0.2)\t8.401\n",
      "80\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.179\n",
      "80\timages/sec: 21.6 +/- 0.0 (jitter = 0.3)\t8.367\n",
      "90\timages/sec: 21.7 +/- 0.0 (jitter = 0.3)\t8.416\n",
      "90\timages/sec: 21.7 +/- 0.0 (jitter = 0.2)\t8.465\n",
      "100\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.351\n",
      "----------------------------------------------------------------\n",
      "total images/sec: 43.29\n",
      "----------------------------------------------------------------\n",
      "100\timages/sec: 21.6 +/- 0.0 (jitter = 0.2)\t8.537\n",
      "----------------------------------------------------------------\n",
      "total images/sec: 43.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs -f {command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That was all! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
